{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from deap import base, creator, tools, algorithms\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import warnings\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('sim_with_razor2.csv')\n",
    "\n",
    "X = dataset[['MET', 'Rsq']].values  \n",
    "y = dataset['Dark Photon Produced'].astype(int).values  \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cls = DecisionTreeClassifier(max_depth=2)\n",
    "def evalModel(individual):\n",
    "    n_estimators, learning_rate = individual\n",
    "    learning_rate = learning_rate / 10\n",
    "\n",
    "    ada_boost = AdaBoostClassifier(base_estimator=base_cls, n_estimators=int(n_estimators), learning_rate=learning_rate)\n",
    "    \n",
    "    ada_boost.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    predictions = ada_boost.predict(X_val_scaled)\n",
    "\n",
    "    accuracy = accuracy_score(y_val, predictions)\n",
    "    return (accuracy,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_n_estimators\", np.random.randint, 50, 400)\n",
    "toolbox.register(\"attr_learning_rate\", np.random.randint, 1, 10)\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                 (toolbox.attr_n_estimators, toolbox.attr_learning_rate), n=1)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evalModel)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutUniformInt, low=[10, 1], up=[400, 50], indpb=0.1)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# toolbox.register(\"select\", tools.selRoulette) # option to make things more interesting if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg     \tstd        \tmin     \tmax     \n",
      "0  \t2     \t0.999951\t9.80392e-06\t0.999941\t0.999961\n",
      "1  \t0     \t0.999961\t0          \t0.999961\t0.999961\n",
      "2  \t2     \t0.999961\t0          \t0.999961\t0.999961\n",
      "3  \t2     \t0.999956\t4.90196e-06\t0.999951\t0.999961\n"
     ]
    }
   ],
   "source": [
    "population = toolbox.population(n=50)\n",
    "hof = tools.HallOfFame(1)  # Hall of Fame to store the best individual\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)\n",
    "\n",
    "\n",
    "result = algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=10, stats=stats, halloffame=hof, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Hyperparameters for AdaBoost:\n",
      "  n_estimators: 391, learning_rate: 0.1\n"
     ]
    }
   ],
   "source": [
    "best_hyperparams = hof.items[0]\n",
    "print(f\"Optimized Hyperparameters for AdaBoost:\")\n",
    "print(f\"  n_estimators: {best_hyperparams[0]}, learning_rate: {best_hyperparams[1]/10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2),\n",
       "                   learning_rate=0.1, n_estimators=391)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2),\n",
       "                   learning_rate=0.1, n_estimators=391)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=2)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=2)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2),\n",
       "                   learning_rate=0.1, n_estimators=391)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_boost = AdaBoostClassifier(base_estimator=base_cls, n_estimators=int(best_hyperparams[0]), learning_rate=(best_hyperparams[1]/10))\n",
    "ada_boost.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of AdaBoost model on entire data set: 0.9999921568627451\n"
     ]
    }
   ],
   "source": [
    "X_random_sample = dataset[['MET', 'Rsq']].values\n",
    "y_random_sample = dataset['Dark Photon Produced'].astype(int).values\n",
    "\n",
    "X_random_sample_scaled = scaler.transform(X_random_sample)\n",
    "\n",
    "random_sample_predictions = ada_boost.predict(X_random_sample_scaled)\n",
    "\n",
    "accuracy_random_sample = accuracy_score(y_random_sample, random_sample_predictions)\n",
    "print(f\"Accuracy of AdaBoost model on entire data set: {accuracy_random_sample}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of AdaBoost model on dark photon produced instances: 0.8518518518518519\n",
      "Predictions on dark photon produced instances: [1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "dark_photon_instances = dataset[dataset['Dark Photon Produced'] == 1]\n",
    "X_dark_photon = dark_photon_instances[['MET', 'Rsq']].values\n",
    "y_dark_photon = dark_photon_instances['Dark Photon Produced'].astype(int).values\n",
    "\n",
    "X_dark_photon_scaled = scaler.transform(X_dark_photon)\n",
    "dark_photon_predictions = ada_boost.predict(X_dark_photon_scaled)\n",
    "\n",
    "accuracy_dark_photon = accuracy_score(y_dark_photon, dark_photon_predictions)\n",
    "print(f\"Accuracy of AdaBoost model on dark photon produced instances: {accuracy_dark_photon}\")\n",
    "print(\"Predictions on dark photon produced instances:\", dark_photon_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Point 1:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 2:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 3:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 4:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 5:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 6:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 7:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 8:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 9:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 10:\n",
      "  Prediction for Dark Photon Produced: No\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 11:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 12:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 13:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 14:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 15:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 16:\n",
      "  Prediction for Dark Photon Produced: No\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 17:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 18:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 19:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 20:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 21:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 22:\n",
      "  Prediction for Dark Photon Produced: No\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 23:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 24:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 25:\n",
      "  Prediction for Dark Photon Produced: No\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 26:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n",
      "Data Point 27:\n",
      "  Prediction for Dark Photon Produced: Yes\n",
      "  Actual: Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (features, label) in enumerate(zip(X_dark_photon, y_dark_photon)):\n",
    "    features_scaled = scaler.transform([features])\n",
    "    prediction = ada_boost.predict(features_scaled)\n",
    "    prediction_result = \"Yes\" if prediction[0] == 1 else \"No\"\n",
    "    actual_result = \"Yes\" if label == 1 else \"No\"    \n",
    "    print(f\"Data Point {i+1}:\")\n",
    "    print(f\"  Prediction for Dark Photon Produced: {prediction_result}\")\n",
    "    print(f\"  Actual: {actual_result}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
