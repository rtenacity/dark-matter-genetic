{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from deap import base, creator, tools\n",
    "import random\n",
    "import pandas as pd\n",
    "from deap import algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('sim_with_razor.csv')\n",
    "\n",
    "X = dataset[['MET', 'Rsq']].values  \n",
    "y = dataset['Dark Photon Produced'].astype(int).values  \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_individual(individual):\n",
    "    model_type = individual[0]\n",
    "    parameter = individual[1]\n",
    "    model_info = {'type': None, 'params': {}}\n",
    "\n",
    "    if model_type == 0:  # Logistic Regression\n",
    "        model_info['type'] = 'LogisticRegression'\n",
    "        C_value = 0.01 + (parameter - 1) * (100 - 0.01) / (10 - 1)\n",
    "        model_info['params']['C'] = C_value\n",
    "\n",
    "    elif model_type == 1:  # Decision Tree\n",
    "        model_info['type'] = 'DecisionTreeClassifier'\n",
    "        model_info['params']['max_depth'] = parameter\n",
    "\n",
    "    elif model_type == 2:  # Random Forest\n",
    "        model_info['type'] = 'RandomForestClassifier'\n",
    "        model_info['params']['n_estimators'] = parameter\n",
    "        model_info['params']['max_depth'] = 5  # Example fixed value\n",
    "\n",
    "    elif model_type == 3:  # Neural Network\n",
    "        model_info['type'] = 'NeuralNetworkClassifier'\n",
    "        if parameter == 1:\n",
    "            layers_config = [64]\n",
    "        elif parameter == 2:\n",
    "            layers_config = [64, 32] \n",
    "        else:\n",
    "            layers_config = [64, 32, 16]\n",
    "        model_info['params']['layers'] = layers_config\n",
    "\n",
    "    return model_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(decoded_individual):\n",
    "    model_type = decoded_individual['type']\n",
    "    params = decoded_individual['params']\n",
    "    model = None\n",
    "\n",
    "    if model_type == 'LogisticRegression':\n",
    "        model = LogisticRegression(**params)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    elif model_type == 'DecisionTreeClassifier':\n",
    "        model = DecisionTreeClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    elif model_type == 'RandomForestClassifier':\n",
    "        model = RandomForestClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    elif model_type == 'NeuralNetworkClassifier':\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(params['layers'][0], input_shape=(X_train_scaled.shape[1],), activation='relu'))\n",
    "        for neurons in params['layers'][1:]:\n",
    "            model.add(tf.keras.layers.Dense(neurons, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # Output layer\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(X_train_scaled, y_train, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "    # Evaluation\n",
    "    if model_type in ['LogisticRegression', 'DecisionTreeClassifier', 'RandomForestClassifier']:\n",
    "        predictions = model.predict(X_val_scaled if model_type == 'LogisticRegression' else X_val)\n",
    "        accuracy = accuracy_score(y_val, (predictions > 0.5).astype(int) if model_type == 'LogisticRegression' else predictions)\n",
    "    else:  # Neural Network\n",
    "        predictions = (model.predict(X_val_scaled) > 0.5).astype(int)\n",
    "        accuracy = accuracy_score(y_val, predictions.flatten())\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(individual):\n",
    "    accuracy = train_model(decode_individual(individual))\n",
    "    return (accuracy,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohanarni/anaconda3/lib/python3.11/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/Users/rohanarni/anaconda3/lib/python3.11/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Define the individual creation function\n",
    "def create_individual():\n",
    "    model_type = random.randint(0, 3)  # 0 to 3 for four model types\n",
    "    if model_type == 0:  # Logistic Regression\n",
    "        parameter = random.randint(1, 10)  # C parameter encoded\n",
    "    elif model_type == 1:  # Decision Tree\n",
    "        parameter = random.randint(1, 15)  # Max Depth\n",
    "    elif model_type == 2:  # Random Forest\n",
    "        parameter = random.randint(10, 100)  # Number of Estimators\n",
    "    else:  # Neural Network\n",
    "        parameter = random.randint(1, 3)  # Simplified to number of layers\n",
    "    return creator.Individual([model_type, parameter])\n",
    "\n",
    "toolbox.register(\"individual\", create_individual)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# Define genetic operators\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutUniformInt, low=[0,1], up=[3,100], indpb=0.2)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"evaluate\", eval_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg     \tmin   \tmax    \n",
      "0  \t2     \t0.999925\t0.9999\t0.99995\n",
      "1  \t2     \t0.99995 \t0.99995\t0.99995\n",
      "2  \t2     \t0.99995 \t0.99995\t0.99995\n",
      "3  \t2     \t0.99995 \t0.99995\t0.99995\n",
      "4  \t2     \t0.99995 \t0.99995\t0.99995\n",
      "5  \t1     \t0.99995 \t0.99995\t0.99995\n"
     ]
    }
   ],
   "source": [
    "population = toolbox.population(n=2)\n",
    "hof = tools.HallOfFame(1)  # Store the best individual\n",
    "\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)\n",
    "\n",
    "result = algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=5, stats=stats, halloffame=hof, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'RandomForestClassifier',\n",
       " 'params': {'n_estimators': 78, 'max_depth': 5}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_individual = hof.items[0]\n",
    "best_model_info = decode_individual(best_individual)\n",
    "best_model_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
